{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb3af6-2da2-475e-a222-4634e489fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM模型\n",
    "#- 内部结构\n",
    "#  - 遗忘门\n",
    "#  - 输入门\n",
    "#  - 输出门\n",
    "#  - 细胞状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0819b8-9e38-4710-9fcb-827c9393843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa2bbb5-15b1-45bd-af5e-dee8dc08f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output--->形状torch.Size([4, 3, 6]),数据值tensor([[[ 0.0662, -0.0389, -0.2212,  0.0290,  0.0122, -0.2783],\n",
      "         [ 0.0953, -0.1418, -0.3685,  0.0343,  0.1081, -0.2238],\n",
      "         [-0.2668,  0.2604,  0.2373, -0.3373,  0.2268,  0.1898]],\n",
      "\n",
      "        [[-0.1333, -0.0545, -0.0813,  0.0300,  0.0232, -0.0005],\n",
      "         [ 0.0244, -0.1951, -0.0147, -0.2366,  0.3981, -0.1313],\n",
      "         [-0.3296,  0.0992, -0.0391, -0.2057,  0.1762,  0.2419]],\n",
      "\n",
      "        [[-0.2034, -0.2550,  0.1651, -0.1275,  0.0413,  0.1855],\n",
      "         [-0.0159, -0.1119,  0.0410, -0.3045,  0.2850, -0.0092],\n",
      "         [-0.2789,  0.0443, -0.1105, -0.0795,  0.1754,  0.2249]],\n",
      "\n",
      "        [[-0.2848, -0.0822, -0.0172, -0.1129,  0.1175,  0.1553],\n",
      "         [-0.0253, -0.3197,  0.3050, -0.2684,  0.3410,  0.0835],\n",
      "         [-0.1476,  0.0139, -0.1506, -0.0091,  0.1660,  0.2654]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "hn--->形状torch.Size([1, 3, 6]),数据值tensor([[[-0.2848, -0.0822, -0.0172, -0.1129,  0.1175,  0.1553],\n",
      "         [-0.0253, -0.3197,  0.3050, -0.2684,  0.3410,  0.0835],\n",
      "         [-0.1476,  0.0139, -0.1506, -0.0091,  0.1660,  0.2654]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "cn--->形状torch.Size([1, 3, 6]),数据值tensor([[[-0.6112, -0.3208, -0.0359, -0.3230,  0.3227,  0.2345],\n",
      "         [-0.0766, -0.5890,  0.5326, -0.9413,  0.5530,  0.1045],\n",
      "         [-0.2903,  0.0319, -0.2471, -0.0173,  0.3107,  0.4750]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def dm_test_lstm():\n",
    "      # 实例化lstm对象\n",
    "      #第一个参数：input_size：输入数据的维度\n",
    "      #第二个参数：hideen_size:隐藏层维度（神经元个数）\n",
    "      # 第三个参数：num_layer,隐藏层层数\n",
    "    lstm = nn.LSTM(5, 6, 1)\n",
    "      # 第一个参数：sequence_length,句子长度\n",
    "      # 第二个参数：batch_size,样本数量（批次）\n",
    "      # 第三个参数：input_size:输入数据的维度\n",
    "    input = torch.randn(4, 3, 5)\n",
    "      # 第一个参数：num_layer*num_dire\n",
    "      # 第二个参数：batch_size,样本数量\n",
    "      # 第三个参数：hidden_size,隐藏层维度\n",
    "    h0 = torch.randn(1, 3, 6)\n",
    "    c0 = torch.randn(1, 3, 6)\n",
    "    output, (hn, cn) = lstm(input, (h0, c0))\n",
    "  \n",
    "    print(f'output--->形状{output.shape},数据值{output}')\n",
    "    print(f'hn--->形状{hn.shape},数据值{hn}')\n",
    "    print(f'cn--->形状{cn.shape},数据值{cn}')\n",
    "dm_test_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2e248-466c-44bf-be00-7236e8b6929c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
