{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef55c372-bef0-4a80-9053-f304bb39db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fee4b597-7324-4eb2-ae37-6e8accd1b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60caebc2-aeb1-4bdc-a53c-8fa48ea12b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed = nn.Embedding(100,3,padding_idx = 0)#补齐 等于什么相同数字部分都会变成0\n",
    "#input = torch.tensor([[1,4,5,9,0],[2,3,4,99,0]])\n",
    "#print(embed(input).shape)\n",
    "#print(embed(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "399c857f-bbd1-48b2-ac19-d4e521bbb6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ -6.7544,  37.2969, -24.1185,  ..., -28.1623, -16.5913, -33.1305],\n",
      "         [-30.0487,  -0.6622,   1.8885,  ..., -21.5260, -10.0797,  25.3691],\n",
      "         [-20.4045,  28.2031, -26.1684,  ...,   7.6636, -15.9720, -11.5723],\n",
      "         [ -6.0887,  -8.3745,  28.9567,  ...,  28.7766,   8.4879,   7.3830]],\n",
      "\n",
      "        [[-16.3278, -45.5139, -19.5662,  ..., -25.9620,  -1.0796,  15.6002],\n",
      "         [ 11.5280,  11.2595, -17.6959,  ...,  31.9375, -23.2782,  12.1726],\n",
      "         [-30.0487,  -0.6622,   1.8885,  ..., -21.5260, -10.0797,  25.3691],\n",
      "         [ -4.7491, -19.5547,   0.9225,  ...,  -0.5921, -45.5901,   6.4347]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#文本嵌入层 将文本变成向量\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self,d_model,vocab):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab #词典的大小\n",
    "        self.d_model = d_model#词嵌入维度的大小\n",
    "        #定义embedding层\n",
    "        self.embed = nn.Embedding(vocab,d_model)\n",
    "    def forward(self,x):\n",
    "        #x[batch_size,seq——len]\n",
    "        embed_x = self.embed(x)\n",
    "        #embed_x乘根号下d_model\n",
    "        #符合标准分布 增加影响\n",
    "        return embed_x*math.sqrt(self.d_model)\n",
    "my_embed = Embeddings(vocab = 1000,d_model = 512)\n",
    "x = torch.tensor([[1,4,7,10],[2,6,4,15]])\n",
    "result = my_embed(x)\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f188c57e-9197-44be-852a-4c9c14bfaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ -7.5525, -18.9474, -37.2853,  ..., -11.1343,  34.7322,  22.2318],\n",
      "         [  9.7805,  -0.0000,  21.4542,  ...,  10.8125,  43.6190, -44.4165],\n",
      "         [-57.4526,  -2.5568,  27.6427,  ...,  38.0741,   0.0000,  -8.3495],\n",
      "         [  9.5816,  -0.0000,  30.8390,  ...,  13.5146, -11.5469,  -3.8992]],\n",
      "\n",
      "        [[ 28.0561,  10.0861, -20.4307,  ...,  -5.9435,  13.0939, -29.4111],\n",
      "         [ 10.0089,  13.3344,  22.0202,  ..., -43.2721,   2.9262,  -6.1910],\n",
      "         [  9.8558,  -1.9507,  21.5815,  ...,  10.8125,  43.6191, -44.4165],\n",
      "         [  9.0348,  -8.0585,  46.9195,  ...,   0.0000,   0.0000, -46.2937]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#位置编码器层 - 1 1  周期性函数  \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,dropout,max_len = 60):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        pe = torch.zeros(max_len,d_model)\n",
    "        #定义位置矩阵【max_len,1】\n",
    "        tem_vec = torch.arange(0,max_len).unsqueeze(1)\n",
    "        #根据公式定义矩阵[256]\n",
    "        div_vec = torch.exp(torch.arange(0,d_model,2)*-math.log(10000.0)/d_model)\n",
    "        #将每个位置先赋值256个向量值\n",
    "        position = tem_vec*div_vec#【60，256】\n",
    "        #pe进行复制\n",
    "        pe[:,0::2] = torch.sin(position)\n",
    "        pe[:,1::2] = torch.cos(position)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        #print(pe.shape)\n",
    "        #[1,60,512]\n",
    "        return self.register_buffer('pe',pe)#缓存区\n",
    "    def forward(self,x):\n",
    "        #x[batch_size,seq_len,512]\n",
    "        #[2,4,512] [1,4,512]\n",
    "        position_x = x + self.pe[:,:x.shape[1]]#广播模式相加\n",
    "        return self.dropout(position_x)\n",
    "my_embed = Embeddings(vocab = 1000,d_model = 512)\n",
    "x = torch.tensor([[1,4,7,10],[2,6,4,15]])\n",
    "result = my_embed(x)\n",
    "print(result.shape)\n",
    "position = PositionalEncoding(d_model = 512,dropout = 0.1)\n",
    "result1 = position(result)\n",
    "print(result1.shape)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2367337-5a2e-4cec-b7a0-9c3728209adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "#掩码张量 掩盖未来的信息防止被提前看到\n",
    "#生成下三角矩阵\n",
    "b = torch.ones((5,5),dtype = torch.long)\n",
    "print(1 - torch.triu(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516bd9ef-2d42-4d66-b7ec-0252773f492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 2.0000, 3.6000],\n",
      "        [3.5000, 2.5000, 3.6000],\n",
      "        [2.5000, 8.2000, 4.3000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = torch.tensor([[1.5,2.0,3.6],[3.5,2.5,3.6],[2.5,8.2,4.3]])\n",
    "b = torch.ones((20,20),dtype = torch.long)\n",
    "mask = 1 - torch.triu(b)\n",
    "#a.masked_fill_(mask == 0,10000)#mask为0的位置对应a出用后面的值进行取代 可以赋值为负无穷经过softmax\n",
    "print(a)\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d30f0a9b-428d-4ba7-b196-ada45767428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_mask(size):\n",
    "    b = torch.ones((1,size,size),dtype = torch.long)\n",
    "    return 1-torch.triu(b,diagonal = 1)\n",
    "#生成下三角矩阵\n",
    "#注意力机制\n",
    "def attention(query,key,value,mask = None,dropout = None):\n",
    "    #三个相等【2，4，512】\n",
    "    #获取dk\n",
    "    d_k = query.size()[-1]\n",
    "    #变换后为【2，4，4】\n",
    "    scores = torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    #如果mask不为孔 需要对分数进行掩码\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill_(mask == 0,-1e9)\n",
    "    #归一化\n",
    "    atten_weights = F.softmax(scores,dim = -1)\n",
    "    #print(atten_weights)\n",
    "    if dropout is not None:\n",
    "        atten_weights = dropout(atten_weights)\n",
    "    return torch.matmul(atten_weights,value),atten_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17e46a9e-0543-4424-a7f8-ae69b041985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def atten_test():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position = my_pe(embed_x)\n",
    "    #子注意力机制\n",
    "    query = value = key = position\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(([2,4,4]))\n",
    "    atten_result,atten_weights = attention(query,key,value,mask = mask)\n",
    "atten_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "226b2b82-2559-49b4-815d-6427cefe7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多头注意力机制\n",
    "def clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self,embed_dim,head,dropout_p):\n",
    "        super().__init__()\n",
    "        #确保整除\n",
    "        assert embed_dim%head == 0\n",
    "        #获取每个头的词嵌入维度\n",
    "        self.d_k = embed_dim // head\n",
    "        self.head = head\n",
    "        #定义四个全连接层\n",
    "        self.linears = clones(module = nn.Linear(embed_dim,embed_dim),N = 4)\n",
    "        self.atten_weight = None\n",
    "        #定义dropout\n",
    "        self.dropout = nn.Dropout(p = dropout_p)\n",
    "    def forward(self,query,key,value,mask = None):#qkv【2，4，512】\n",
    "        #mask[head,seq_len,seq_len][8,4,4]\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(0)#[1,8,4,4]\n",
    "        batch_size = query.size()[0]\n",
    "        #三个参数都要经过linear层【2，8，4，64】\n",
    "        query,key,value = [model(x).view(batch_size,-1,self.head,self.d_k).transpose(1,2) for model,x in zip(self.linears,(query,key,value))]\n",
    "        #atten_weight[2,8,4,4]  *[2,8,4,64]--- x[2,8,4,64]\n",
    "        x,atten_weight = attention(query,key,value,mask = mask,dropout = self.dropout) \n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.head*self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "#MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "636c737a-084e-4873-9fbc-31b4c9da587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "torch.Size([2, 4, 512])\n",
      "tensor([[[11.8092,  4.2623,  5.0701,  ..., -1.8925,  6.0733,  3.8997],\n",
      "         [10.4560,  7.4084,  5.9079,  ..., -1.2302,  6.4411,  5.9858],\n",
      "         [ 7.8284,  4.6580,  5.0052,  ..., -1.2747,  2.3641,  3.4647],\n",
      "         [ 7.6787,  6.0714,  6.6178,  ..., -2.0894,  6.2263,  3.6953]],\n",
      "\n",
      "        [[ 2.7854,  0.5934,  1.5577,  ..., -0.4511,  5.1985,  6.7118],\n",
      "         [ 0.1875,  4.4717,  6.6285,  ...,  0.8038,  4.6550,  4.2542],\n",
      "         [ 4.4418,  1.9698,  1.7667,  ...,  2.0101,  6.0259,  7.6964],\n",
      "         [ 3.1796,  4.7967,  4.8866,  ...,  1.6901,  4.3945,  6.0396]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def mulatten_test():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position = my_pe(embed_x)\n",
    "    #子注意力机制\n",
    "    query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    atten_result = mha(query,key,value,mask = mask)\n",
    "    print(atten_result.shape)\n",
    "    print(atten_result)\n",
    "mulatten_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38bb3c24-70e9-4ac9-a548-2cf9ec8ddcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#前馈全连接层\n",
    "#怕拟合程度不够\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        #d_model 词嵌入维度\n",
    "        #d_ff前馈全连接层内部维度\n",
    "        self.linear1 = nn.Linear(d_model,d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff,d_model)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self,x):\n",
    "        #来自多头注意力机制的结果\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b68b04a-cf79-498d-a227-290145115c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#前馈验证\n",
    "def mulatten_test1():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position = my_pe(embed_x)\n",
    "    #子注意力机制\n",
    "    query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    atten_result = mha(query,key,value,mask = mask)\n",
    "    FF = PositionwiseFeedForward(d_model = 512,d_ff = 1024)\n",
    "    dd = FF(atten_result)\n",
    "    print(dd)\n",
    "    print(dd.shape)\n",
    "#mulatten_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e0ecc76-8520-4d9c-8e2a-290d29b12522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#规范化NORM  参数可能出现过大过小\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,features,eps = 1e-6):\n",
    "        #features词嵌入维度\n",
    "        super().__init__()\n",
    "        self.a2 = nn.Parameter(torch.ones(features))\n",
    "        self.b2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "    def forward(self,x):\n",
    "        #可能来自多头自注意力基质层  也可能来自全连接层\n",
    "        mean = x.mean(-1,keepdim = True)#维度 保持维度\n",
    "        std = x.std(-1,keepdim = True)\n",
    "        y = self.a2*(x-mean)/(std+self.eps)+self.b2\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b7508ab-1f19-421a-99c3-d38456246590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 1.4384,  0.8725,  1.2850,  ...,  0.3009, -0.8368,  0.0424],\n",
      "         [ 1.3506,  0.5128,  1.3128,  ..., -0.1910, -1.0263, -1.2274],\n",
      "         [ 1.0862,  0.8063,  1.0711,  ...,  0.6493, -1.0836,  0.1024],\n",
      "         [ 1.8049,  1.2287,  0.6459,  ...,  1.2812, -0.4966, -0.0984]],\n",
      "\n",
      "        [[ 0.0987,  0.8129, -1.4800,  ..., -1.5322, -1.7377,  0.1285],\n",
      "         [ 1.3390,  1.5090,  0.0161,  ..., -1.4087, -1.4111, -0.5301],\n",
      "         [-0.4715,  1.2316, -0.2710,  ..., -0.7487, -1.6661,  0.0848],\n",
      "         [-0.4175,  2.1687, -0.1236,  ..., -1.4652, -1.5370,  0.1060]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#规范层验证\n",
    "def mulatten_test2():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position = my_pe(embed_x)\n",
    "    #子注意力机制\n",
    "    query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    atten_result = mha(query,key,value,mask = mask)\n",
    "    FF = PositionwiseFeedForward(d_model = 512,d_ff = 1024)\n",
    "    dd = FF(atten_result)\n",
    "    layer_norm = LayerNorm(features=512)\n",
    "    result = layer_norm(dd)\n",
    "    print(result)\n",
    "    print(result.shape)\n",
    "    #print(dd)\n",
    "    #print(dd.shape)\n",
    "mulatten_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db9cf612-00a4-47c1-b279-a018c5602d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#子层连接层add\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self,size,dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "    def forward(self,x,sublayer):\n",
    "        #x【2，4，512】\n",
    "        myres = x + self.dropout(sublayer(self.norm(x)))#add和norm顺序没有区别\n",
    "        return myres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0de230e-cf2c-4a14-bfc7-7f58d929502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 1.5706e+01, -2.4468e+01, -1.8880e+00,  ..., -1.0895e+01,\n",
      "           7.1159e+00,  4.8198e+00],\n",
      "         [ 1.1906e+01,  4.4871e+00, -1.5791e+01,  ..., -1.4944e+01,\n",
      "           3.8546e+01,  3.4934e+01],\n",
      "         [ 4.0516e+00,  3.6136e+01, -8.6978e+00,  ...,  5.3842e+01,\n",
      "          -1.6244e-01, -2.0297e-02],\n",
      "         [ 2.7764e+00, -1.5614e+00, -7.4572e-02,  ..., -2.2466e+01,\n",
      "          -5.0818e+01, -1.1938e+00]],\n",
      "\n",
      "        [[ 1.1019e+01, -2.0102e-01, -1.6631e+01,  ..., -1.5112e+01,\n",
      "           3.8410e+01,  3.4890e+01],\n",
      "         [ 2.0349e+01, -3.5357e+01, -4.6927e+01,  ...,  3.2270e+00,\n",
      "          -1.0225e+01, -1.0961e+01],\n",
      "         [-5.5331e+01, -1.9672e-01, -4.9578e+01,  ..., -1.8207e+01,\n",
      "          -1.3440e-01, -3.6506e+01],\n",
      "         [-1.0689e+01,  8.1743e+00,  6.4239e-02,  ..., -3.4057e+01,\n",
      "          -2.0198e+01, -3.5532e+01]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#子层验证\n",
    "def mulatten_test3():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_x = my_pe(embed_x)\n",
    "    ##子注意力机制\n",
    "    #query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    #定义匿名函数\n",
    "    sub_layer = lambda x:mha(x,x,x,mask)\n",
    "    #实例化子层\n",
    "    sub_connection = SublayerConnection(size = 512)\n",
    "    result = sub_connection(x = position_x,sublayer = sub_layer)\n",
    "    print(result)\n",
    "    print(result.shape)\n",
    "mulatten_test3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "273b76ba-4dda-4a41-a414-d022e70f7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#编码器层\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,size,self_atten,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        self.self_atten = self_atten#多头自注意力对象\n",
    "        self.feed_forward = feed_forward#前馈全连接对象\n",
    "        self.size = size\n",
    "        self.sublayer = clones(SublayerConnection(size,dropout),2)\n",
    "    def forward(self,x,mask):\n",
    "        x = self.sublayer[0](x,lambda x:self.self_atten(x,x,x,mask))\n",
    "        x = self.sublayer[1](x,self.feed_forward)#依次经过两个层\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bc49186-cb65-4c5d-9027-94179f0dddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,layer,N):\n",
    "        #layer编码器层的对象\n",
    "        #N几个编码器层\n",
    "        super().__init__()\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    def forward(self,x,mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a64e3692-e91a-4863-b5b2-4462aa024612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 512])\n",
      "tensor([[[ 1.2999, -0.4339, -0.1345,  ...,  0.9604,  0.1954,  1.2850],\n",
      "         [-0.9645, -0.0490,  0.4566,  ..., -0.4068,  1.8088, -0.7653],\n",
      "         [-0.3235,  0.0750, -0.0888,  ...,  1.0849,  1.3690,  0.7425],\n",
      "         [ 1.1165, -0.8784, -1.3966,  ..., -0.6248, -0.0919, -0.2160]],\n",
      "\n",
      "        [[-1.0167,  1.1258,  0.4500,  ..., -0.4585,  1.8682, -0.7280],\n",
      "         [ 2.1911, -0.4705,  0.0912,  ..., -0.1647,  0.0665,  0.7762],\n",
      "         [ 0.6705, -0.2031, -0.4864,  ..., -0.0090,  1.7999, -0.0572],\n",
      "         [ 1.1292, -1.4844, -1.3975,  ..., -0.9830,  0.2841,  1.6894]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "#子层验证\n",
    "def mulatten_test4():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_x = my_pe(embed_x)\n",
    "    ##子注意力机制\n",
    "    #query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    #前馈层\n",
    "    FF = PositionwiseFeedForward(d_model = 512,d_ff = 1024)\n",
    "    #实例化编码器对象\n",
    "    encoder_layer = EncoderLayer(size = 512,self_atten = mha,feed_forward = FF,dropout = dropout_p)\n",
    "    #实例化编码器对象\n",
    "    encoder = Encoder(layer = encoder_layer,N = 6)\n",
    "    encoder_x = encoder(position_x,mask)\n",
    "    print(encoder_x)\n",
    "    print(encoder_x.shape)\n",
    "mulatten_test4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7d75d87-cec5-4fe7-8815-80f04b035794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#解码器 有三个子层结构构成\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,size,self_attn,src_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        #size词嵌入维度\n",
    "        self.size = size\n",
    "        #self_attn  自注意力机制\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        #feed_forward 全连接层\n",
    "        self.feed_forward = feed_forward\n",
    "        #克隆三个子层\n",
    "        self.sub_layers = clones(SublayerConnection(size,dropout),3)\n",
    "    def forward(self,y,encoder_output,source_mask,target_mask):\n",
    "        #y来自解码器端的输入【2，4，512】\n",
    "        #encoder_output来自编码器的输出\n",
    "        #sourece_mask  作用到第二个子层结构的多头注意力机制进行padding_mask\n",
    "        #target_mask 进行sentence_mask 多头自注意力机制\n",
    "        y1 = self.sub_layers[0](y,lambda x:self.self_attn(x,x,x,target_mask))\n",
    "        y2 = self.sub_layers[1](y1,lambda x:self.src_attn(x,encoder_output,encoder_output,source_mask))\n",
    "        y3 = self.sub_layers[2](y2,self.feed_forward)\n",
    "        return y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "123991a1-88ac-4f3a-8200-c7fdd818edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.5052e+01,  2.1487e+01,  8.1139e+00,  ...,  3.0218e+01,\n",
      "           1.0135e+01,  2.4080e+01],\n",
      "         [ 5.9306e+00, -2.0728e+01,  1.3439e-01,  ..., -3.9567e+01,\n",
      "          -2.0678e+01,  7.6335e+00],\n",
      "         [-1.9168e+01, -1.6029e+01, -3.4322e+01,  ..., -8.4429e+00,\n",
      "           7.5128e+00, -1.1718e+01],\n",
      "         [-1.2867e+01,  2.5424e+01, -5.3347e-01,  ..., -6.1304e+01,\n",
      "           7.5067e+00,  8.5168e+00],\n",
      "         [-8.1537e+00,  6.0623e+00,  3.7803e+00,  ...,  3.6756e+00,\n",
      "          -4.5317e-01,  8.5816e+00],\n",
      "         [ 4.0465e+00, -2.1095e+01, -2.3209e+01,  ..., -3.9708e+01,\n",
      "          -2.0616e+01,  7.7159e+00]],\n",
      "\n",
      "        [[-3.8565e+00, -2.1795e+01,  2.1962e+01,  ...,  1.5400e+01,\n",
      "           6.6356e+00,  3.6792e+01],\n",
      "         [ 5.5003e+00, -2.1184e+01, -2.1035e+01,  ...,  6.8035e-02,\n",
      "          -2.0461e+01,  4.4088e-02],\n",
      "         [-1.2127e-01,  1.9540e+01,  9.4359e+00,  ...,  3.0282e+01,\n",
      "           1.0404e+01,  2.4559e+01],\n",
      "         [ 4.7052e+00, -4.0239e+01,  4.8039e+01,  ...,  2.5456e+01,\n",
      "           1.1123e+01,  1.4787e+01],\n",
      "         [ 2.3260e+01, -6.1830e-01, -1.7070e+01,  ...,  4.5162e+01,\n",
      "           7.6913e+00,  2.5359e+01],\n",
      "         [-4.8020e+00, -2.2288e+01,  2.1033e+01,  ...,  1.5310e+01,\n",
      "           6.2177e+00,  6.2468e-02]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "#子层验证\n",
    "def mulatten_test5():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    #解码器输入\n",
    "    y = torch.tensor([[1,3,56,4,5,3],\n",
    "                      [2,3,1,76,34,2]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    #词嵌入层的结果\n",
    "    embed_y = my_embed(y)\n",
    "    #print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_x = my_pe(embed_x)\n",
    "    my_pe_y = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_y = my_pe(embed_y)\n",
    "    ##子注意力机制\n",
    "    #query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    self_atten = copy.deepcopy(mha)\n",
    "    src_atten = copy.deepcopy(mha)\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    #前馈层\n",
    "    FF = PositionwiseFeedForward(d_model = 512,d_ff = 1024)\n",
    "    #实例化编码器对象\n",
    "    encoder_layer = EncoderLayer(size = 512,self_atten = mha,feed_forward = FF,dropout = dropout_p)\n",
    "    #实例化编码器对象 编码器输出\n",
    "    encoder = Encoder(layer = encoder_layer,N = 6)\n",
    "    encoder_x = encoder(position_x,mask)\n",
    "    #实例化解码器曾\n",
    "    decoder_layer = DecoderLayer(size = 512,self_attn=self_atten,src_attn=src_atten,feed_forward=FF,dropout=0.1)\n",
    "    #输出获取\n",
    "    target_mask = torch.zeros(8,6,6)\n",
    "    source_mask = torch.zeros(8,6,4)\n",
    "    decoder_y = decoder_layer(position_y,encoder_x,source_mask,target_mask)\n",
    "    print(decoder_y)\n",
    "    print(decoder_y.shape)\n",
    "mulatten_test5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fd30b0e-73b5-407d-ad83-6a8d688c2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):#六个解码器堆叠而成\n",
    "    def __init__(self,layer,N):\n",
    "        #layer编码器层的对象\n",
    "        #N几个编码器层\n",
    "        super().__init__()\n",
    "        #克隆六个解码器层 然后规范化\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    def forward(self,y,encoder_output,source_mask,target_mask):\n",
    "        for layer in self.layers:\n",
    "            y = layer(y,encoder_output,source_mask,target_mask)\n",
    "        return self.norm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9787a16b-8ea3-45f8-a4a4-24c2a754c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#子层验证\n",
    "def mulatten_test6():\n",
    "    vocab = 1000\n",
    "    d_model = 512\n",
    "    x = torch.tensor([[1,2,3,10],[2,5,25,6]])\n",
    "    #解码器输入\n",
    "    y = torch.tensor([[1,3,56,4,5,3],\n",
    "                      [2,3,1,76,34,2]])\n",
    "    my_embed = Embeddings(vocab=vocab,d_model=d_model)\n",
    "    embed_x = my_embed(x)\n",
    "    #词嵌入层的结果\n",
    "    embed_y = my_embed(y)\n",
    "    #print(embed_x.shape)\n",
    "    #位置编码器层\n",
    "    dropout_p = 0.1\n",
    "    my_pe = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_x = my_pe(embed_x)\n",
    "    my_pe_y = PositionalEncoding(d_model = d_model,dropout = dropout_p)\n",
    "    position_y = my_pe(embed_y)\n",
    "    ##子注意力机制\n",
    "    #query = value = key = position\n",
    "    #实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim = 512,head = 8,dropout_p = 0.1 )\n",
    "    self_atten = copy.deepcopy(mha)\n",
    "    src_atten = copy.deepcopy(mha)\n",
    "    #atten_result,atten_weights = attention(query,key,value)\n",
    "    #print(atten_result.shape)\n",
    "    #print(atten_weights.shape)\n",
    "    #假如加入掩码\n",
    "    mask = torch.zeros(8,4,4)\n",
    "    #前馈层\n",
    "    FF = PositionwiseFeedForward(d_model = 512,d_ff = 1024)\n",
    "    #实例化编码器对象\n",
    "    encoder_layer = EncoderLayer(size = 512,self_atten = mha,feed_forward = FF,dropout = dropout_p)\n",
    "    #实例化编码器对象 编码器输出\n",
    "    encoder = Encoder(layer = encoder_layer,N = 6)\n",
    "    encoder_x = encoder(position_x,mask)\n",
    "    #实例化解码器曾\n",
    "    decoder_layer = DecoderLayer(size = 512,self_attn=self_atten,src_attn=src_atten,feed_forward=FF,dropout=0.1)\n",
    "    #输出获取\n",
    "    target_mask = torch.zeros(8,6,6)\n",
    "    source_mask = torch.zeros(8,6,4)\n",
    "    decoder = Decoder(layer = decoder_layer,N=6)\n",
    "    decoder_y = decoder(position_y,encoder_x,source_mask,target_mask)\n",
    "    #print(decoder_y)\n",
    "    #print(decoder_y.shape)\n",
    "    return decoder_y\n",
    "#mulatten_test6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afe1e583-ade8-492e-95b6-4cbbeec523ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出部分\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,d_model,vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model,vocab_size)\n",
    "    def forward(self,x):\n",
    "        output = F.log_softmax(self.linear(x),dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0410c262-5095-4cd2-aba6-2fc48424a1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.2113, -7.8165, -5.8851,  ..., -7.0307, -7.7632, -8.3303],\n",
      "         [-6.4520, -7.1907, -6.3119,  ..., -5.7509, -6.6670, -7.5028],\n",
      "         [-7.6302, -7.3221, -6.9720,  ..., -6.8376, -7.2300, -8.6525],\n",
      "         [-6.6505, -7.2964, -7.2392,  ..., -7.2409, -6.9483, -6.8828],\n",
      "         [-8.2321, -6.7786, -6.9768,  ..., -7.6143, -6.6167, -7.8379],\n",
      "         [-6.8069, -7.3579, -6.6878,  ..., -5.7800, -6.6732, -7.2197]],\n",
      "\n",
      "        [[-7.7017, -7.2580, -7.7722,  ..., -7.4994, -7.2380, -6.7077],\n",
      "         [-6.5475, -7.1416, -6.6934,  ..., -5.8362, -6.5000, -7.5549],\n",
      "         [-5.7618, -7.3783, -5.9692,  ..., -7.0009, -7.6335, -8.3488],\n",
      "         [-6.2405, -6.2852, -7.1437,  ..., -7.9032, -7.0266, -6.9648],\n",
      "         [-6.3886, -6.6969, -7.0498,  ..., -7.3733, -7.9428, -5.9402],\n",
      "         [-7.4892, -7.2588, -7.9886,  ..., -7.2907, -6.9577, -6.5501]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([2, 6, 1000])\n"
     ]
    }
   ],
   "source": [
    "decoder_y = mulatten_test6()\n",
    "generator = Generator(d_model = 512,vocab_size=1000)\n",
    "output = generator(decoder_y)\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25d16712-c40a-4d7b-801c-393283c8979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder,source_embed,target_embed,generator):\n",
    "        super().__init__()\n",
    "        self.encoder= encoder\n",
    "        self.decoder = decoder\n",
    "        #source_embed 位置编码器对象\n",
    "        self.source_embed = source_embed\n",
    "        self.target_embed = target_embed#目标语言\n",
    "        self.generator = generator\n",
    "    def forward(self,source,target,source_mask1,source_mask2,target_mask):\n",
    "        #元语言的输入 目标语言的输入  padding_mask sentence_mask\n",
    "        #将原始的source送入输入部分变成【2，4，512】\n",
    "        encoder_word_embed = self.source_embed(source)\n",
    "        encoder_output = self.encoder(encoder_word_embed,source_mask1)\n",
    "        decoder_word_embed = self.target_embed(target)\n",
    "        decoder_output = self.decoder(decoder_word_embed,encoder_output,source_mask2,target_mask)\n",
    "        output = self.generator(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1212c73-6377-4720-b771-73efcf675193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoder(\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_atten): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sublayer): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (src_attn): MultiHeadedAttention(\n",
      "          (linears): ModuleList(\n",
      "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (sub_layers): ModuleList(\n",
      "          (0): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): SublayerConnection(\n",
      "            (norm): LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm()\n",
      "  )\n",
      "  (source_embed): Sequential(\n",
      "    (0): Embeddings(\n",
      "      (embed): Embedding(1000, 512)\n",
      "    )\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (target_embed): Sequential(\n",
      "    (0): Embeddings(\n",
      "      (embed): Embedding(1000, 512)\n",
      "    )\n",
      "    (1): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (linear): Linear(in_features=512, out_features=2000, bias=True)\n",
      "  )\n",
      ")\n",
      "transformer模型最终的输出结果--》tensor([[[-8.1369, -7.9801, -7.7423,  ..., -8.0296, -6.6149, -6.6323],\n",
      "         [-7.3993, -7.8676, -7.1905,  ..., -6.3995, -7.5042, -7.6982],\n",
      "         [-7.1170, -6.6222, -8.0663,  ..., -7.6640, -7.0937, -7.4563],\n",
      "         [-7.9249, -6.9776, -6.9148,  ..., -7.2784, -6.8278, -7.8960],\n",
      "         [-7.2386, -7.6921, -8.2602,  ..., -8.0143, -8.4553, -7.3894],\n",
      "         [-7.7278, -7.7538, -7.3959,  ..., -7.7398, -7.7551, -8.0788]],\n",
      "\n",
      "        [[-7.9415, -6.8727, -8.7890,  ..., -7.0603, -8.9111, -8.6189],\n",
      "         [-7.8013, -7.4524, -7.7207,  ..., -8.1257, -8.0200, -8.5115],\n",
      "         [-7.9582, -6.9919, -8.5218,  ..., -7.5434, -7.4663, -8.3251],\n",
      "         [-8.1717, -8.5220, -8.0129,  ..., -6.7597, -7.6029, -7.6626],\n",
      "         [-8.1993, -7.6313, -7.9397,  ..., -7.0624, -6.6535, -6.6957],\n",
      "         [-8.2222, -7.6754, -8.5866,  ..., -7.0690, -7.2798, -7.9487]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "transformer模型最终的输出结果--》torch.Size([2, 6, 2000])\n"
     ]
    }
   ],
   "source": [
    "def test_transformer():\n",
    "    # 1.实例化编码器对象\n",
    "    # 实例化多头注意力机制的对象\n",
    "    mha = MultiHeadedAttention(embed_dim=512, head=8, dropout_p=0.1)\n",
    "    # 实例化前馈全连接层对象\n",
    "    ff = PositionwiseFeedForward(d_model=512, d_ff=1024)\n",
    "    encoder_layer = EncoderLayer(size=512, self_atten=mha, feed_forward=ff, dropout=0.1)\n",
    "    encoder = Encoder(layer=encoder_layer, N=6)\n",
    "\n",
    "    # 2.实例化解码器对象\n",
    "    self_attn = copy.deepcopy(mha)\n",
    "    src_attn = copy.deepcopy(mha)\n",
    "    feed_forward = copy.deepcopy(ff)\n",
    "    decoder_layer = DecoderLayer(size=512, self_attn=self_attn, src_attn=src_attn, feed_forward=feed_forward, dropout=0.1)\n",
    "    decoder = Decoder(layer=decoder_layer, N=6)\n",
    "\n",
    "    # 3.源语言输入部分的对象：wordEmbedding+PostionEncoding\n",
    "    # 经过Embedding层\n",
    "    vocab_size = 1000\n",
    "    d_model = 512\n",
    "    encoder_embed = Embeddings(vocab=vocab_size, d_model=d_model)\n",
    "    # 经过位置编码器层（在位置编码器内部，我们其实已经融合来embed_x）\n",
    "    dropout_p = 0.1\n",
    "    encoder_pe = PositionalEncoding(d_model=d_model, dropout=dropout_p)\n",
    "    source_embed = nn.Sequential(encoder_embed, encoder_pe)#封装融合\n",
    "    # 4.目标语言输入部分的对象：wordEmbedding+PostionEncoding\n",
    "    # 经过Embedding层\n",
    "    decoder_embed = copy.deepcopy(encoder_embed)\n",
    "    # 经过位置编码器层（在位置编码器内部，我们其实已经融合来embed_x）\n",
    "    decoder_pe = copy.deepcopy(encoder_pe)\n",
    "    target_embed = nn.Sequential(decoder_embed, decoder_pe)\n",
    "\n",
    "    # 5.实例化输出对象\n",
    "    generator = Generator(d_model=512, vocab_size=2000)\n",
    "\n",
    "    # 6.实例化EncoderDecoder对象\n",
    "    transformer = EncoderDecoder(encoder, decoder, source_embed, target_embed, generator)\n",
    "    print(transformer)\n",
    "\n",
    "    # 7.准备数据\n",
    "    source = torch.tensor([[1, 2, 3, 4],\n",
    "                           [2, 5, 6, 10]])\n",
    "    target = torch.tensor([[1, 20, 3, 4, 19, 30],\n",
    "                           [21, 5, 6, 10, 80,38]])\n",
    "    source_mask1 = torch.zeros(8, 4, 4)\n",
    "    source_mask2 = torch.zeros(8, 6, 4)\n",
    "    target_mask = torch.zeros(8, 6, 6)\n",
    "    result = transformer(source, target, source_mask1, source_mask2, target_mask)\n",
    "    print(f'transformer模型最终的输出结果--》{result}')\n",
    "    print(f'transformer模型最终的输出结果--》{result.shape}')\n",
    "test_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ff079-7676-4ed3-b31b-75f31554e010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
